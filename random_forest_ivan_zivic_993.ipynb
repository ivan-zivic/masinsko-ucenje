{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <center> Uvod </center> \n",
    "\n",
    "Stabla odluke se u mašinskom učenju upotrebljavaju u svrhu klasifikacije željenih instanci, odnosno određivanja vrednosti nepoznatog klasnog atributa.\n",
    "\n",
    "Prednost korišćenja stabla odluke za klasifikaciju je jednostavnija realizacija, ali i razumevanje. Naime, pri vizuelizaciji stabla odluke, prateći svaku putanju od korenog čvora pa do svakog lista, vrlo jednostavno, govornim jezikom može se pročitati kako će se vršiti klasifikacija i koji je redosled pitanja na koji će algoritam odgovarati pri klasifikaciji instanci.\n",
    "\n",
    "Nedostaci korišćenja stabla odluke ogledaju se u tome da se generisano stablo može previše \"navići\" na trening skup koji se koristio pri generisanju stabla odluke. Ova pojava se naziva prenaučenje, odnosno *overfitting*. Posledica prenaučenja je ta da će stablo davati odlične rezultate pri klasifikaciji instanci koje čine trening skup, a davati loše rezultate pri klasifikaciji instanci koje ne pripadaju trening skupu i nisu učestvovale pri generisanju stabla odluke (npr. instance koje se nalaze u test skupu). Do prenaučenja dolazi kada se svaki list stabla odluke generiše tek kada se utvrdi homogenost skupa. Da bi se izbeglo prenaučenje stabla odluke, koristi se odsecanje stabla, odnosno *pruning*. Pod odsecanjem, podrazumevaju se sve taktike koje će smanjiti veličinu, odnosno kompleksnost stabla odluke i smanjiti efekat prenaučenja. Jedna od taktika koje se mogu primenjivati prilikom odsecanja stabla, može biti ograničenje skupa instanci ispod koje se dalje ne vrši razbijanje skupa, čak i u slučaju da skup nije homogen, tako da se list generiše i u situaciji kada entropija datog skupa nije jednaka nuli (klasifikacija će biti izvršena na osnovu klase kojoj pripada najveći broj instanci iz skupa). Druga taktika može biti ograničenje dubine stabla odluke itd.\n",
    "\n",
    "*Random forest* algoritam, pri klasifikaciji koristi grupu, odnosno ansambl stabala odluke. Svako stablo koje čini ansambl vrši svoju individualnu klasifikaciju, a do konačne klasifikacije dolazi se \"brojanjem glasova\". Ona klasa koja je \"izglasana\" najveći broj puta, računa se kao konačna klasa date instance čija je klasifikacija vršena.\n",
    "U *random forest* algoritmu svako stablo se generiše u potpunosti, odnosno ne koristi se odsecanje individualnog stabla. Efekat prenaučenja kome je podložno individualno stablo odluke smanjuje se korišćenjem grupe različitih stabala. Svako stablo se generiše na osnovu instanci koje se biraju nasumično iz inicijalnog skupa podataka, a za razliku od korišćenja individualnog stabla odluke, gde instance ne smeju biti ponavljanje u trening skupu, kod *random forest* algoritma to je dozvoljeno (takav skup se naziva **bootsrapped** skup). \n",
    "\n",
    "Pod odsecanjem u *random forest* terminologiji podrazumeva se smanjenje broja stabala koja čine ansambl. Naime, na prvi pogled može se učiniti da se povećanjem broja stabala u ansamblu vrši i preciznija klasifikacija instanci. To će i biti slučaj, ali samo do određene veličine ansambla. Nakon ovog broja, odnosno generisanjem većeg broja stabala odluke, tačnost klasifikacije će se smanjivati.\n",
    "\n",
    "Nije poznat tačan kriterijum kako doći do optimalnog broja stabala u ansamblu za koji će klasifikacija biti najtačnija, već programeri vrše testiranje menjanjem parametara (povećanje i smanjenje broja generisanih stabala).\n",
    "U daljem izveštaju sledi implementacija *random forest* algoritma, kao i objašnjenje svakog dela koda. Algoritam vrši klasifikaciju instanci (osoba) na one koje imaju, odnosno one koje nemaju šećernu bolest. Skup podataka preuzet je sa adrese: https://www.mldata.io/dataset-details/pima_native_american_diabetes/, a podaci su prikupljeni uzimanjem uzoraka krvi američkih starosedelaca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najpre je potrebno učitati pomoćne biblioteke. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2014,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from pprint import pprint\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zatim, učitava se *csv* fajl koji sadrži podatke. Filtriranje kolona, koje se postiže navođenjem imena istih, upotrebjeno je u svrhu korektnog sortiranja kolona, za potrebe pomoćnih funkcija, od kojih pojedine (kao na primer funkcija za računanje entropije) zahteva da se atribut, odnosno kolona na osnovu koje se klasifikacija vrši, nađe kao poslednja kolona u *data frame*-u.   \n",
    "\n",
    "Sa druge strane, ovo su kolone koje su relevantne za kreiranje modela, odnosno koje će učestvovati prilikom klasifikacije željene instance (samim tim obezbeđeno je filtriranje kolona koje ne nose nikakve relevantne informacije za kreiranje modela kao što može biti kolona *ID* na primer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2015,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pima_native_american_diabetes_weka_dataset.csv')\n",
    "df = df[['times_pregnant', 'plasma_glucose', 'diastolic_blood_pressure',\n",
    "'tricep_skin_fold_thickness', 'serum_insulin', 'body_mass_index',\n",
    " 'diabetes_pedigree_function', 'age', 'class']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Random forest* algoritam treba da ima implementiran mehanizam koji može da radi sa nepotpunim podacima. U tu svrhu, pre generisanja stabala, potrebno je pretprocesirati inicijalne podatke. U konkretnom primeru, odnosno skupu, nepotpuni podaci su označeni nulom, tako da funkcija **replace_missing_values** vrši zamenu nula u svim kolonama prosečnim vrednostima koje se javljaju u odgovarajućoj koloni (izuzev u kolonama *times_pregnant* i *class*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2016,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_missing_values(df):\n",
    "\n",
    "    averige = df.mean()\n",
    "    df = df.replace({'plasma_glucose': {0: averige['plasma_glucose']},\n",
    "                     'diastolic_blood_pressure': {0: averige['diastolic_blood_pressure']},\n",
    "                     'tricep_skin_fold_thickness': {0: averige['tricep_skin_fold_thickness']},\n",
    "                     'serum_insulin': {0: averige['serum_insulin']},\n",
    "                     'body_mass_index': {0: averige['body_mass_index']},\n",
    "                     'diabetes_pedigree_function': {0: averige['diabetes_pedigree_function']},\n",
    "                     'age': {0: averige['age']}})\n",
    "\n",
    "    df = df.replace({'class': {0: 'negative'}})\n",
    "    df = df.replace({'class': {1: 'positive'}})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija **determine_best_features** vrši sortiranje atributa od onog koji je najbitniji pa prema manje bitnim atributima, gledajući prema atributu koji je potrebno odrediti (klasnom atributu). Funkcija koristi pomoć **sklearn** biblioteke, koja ima razne načine na koje može da utvrdi relevantnost atributa na osnovu raznih statističkih testova. Konkretno, u funkciji je upotrebjen **chi squared** test.\n",
    "\n",
    "Cilj testiranja relevantnosti atributa je eliminisanje onih nebitnih, odnosno manje bitnih kolona u cilju smanjenja robusnosti podataka i poboljšanja performansi aplikacije.\n",
    "\n",
    "Funkcija vraca dvodimenzionalno **numpy** polje, gde je prvi element svake vrste naziv atributa, a drugi skor koji je atribut postigao na testu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2017,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_features(df):\n",
    "    # Split the data into input and target\n",
    "    X = df.iloc[:, 0:8]\n",
    "    Y = df.iloc[:, 8]\n",
    "    # We will select the features using chi square\n",
    "    test = SelectKBest(score_func=chi2, k=8)\n",
    "    # Fit the function for ranking the features by score\n",
    "    fit = test.fit(X, Y)\n",
    "    best_scores = fit.scores_\n",
    "    columns = X.columns.values\n",
    "    #print(columns)\n",
    "    #print(best_scores)\n",
    "    columns_dataframe = pd.DataFrame(columns)\n",
    "    best_scores_dataframe = pd.DataFrame(best_scores)\n",
    "    joined_dataframe = pd.concat([columns_dataframe, best_scores_dataframe], axis=1)\n",
    "    joined_dataframe.columns = ['features', 'scores']\n",
    "    #print('udruzeno:')\n",
    "    #print(joined_dataframe)\n",
    "    sorted_joined_dataframe = joined_dataframe.nlargest(8, 'scores')\n",
    "    return sorted_joined_dataframe.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija **keep_most_relevant_features** vrši filtriranje prosleđenog skupa podataka, zadržavajući samo onoliko atributa (kolona) predstavljeno brojem koji se prosledi preko **number_of_features_to_keep** atributa. Atribut **best_features_sorted** sadrži sortirane atribute, počevši od najbitnijeg pa prema onim manje bitnim atributima.\n",
    "\n",
    "Funkcija vraća filtriran skup podataka, odbacujući manje bitne kolone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2018,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_most_relevant_features(df, number_of_features_to_keep, best_features_sorted):\n",
    "    if number_of_features_to_keep > 0 and number_of_features_to_keep <= 8:\n",
    "        list_of_features_to_keep = []\n",
    "        for i in range(number_of_features_to_keep):\n",
    "            list_of_features_to_keep.append(best_features_sorted[i, 0])\n",
    "        list_of_features_to_keep.append('class')\n",
    "        df = df[list_of_features_to_keep]\n",
    "    #print(list_of_features_to_keep)\n",
    "    #print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija *train_test_split* vrši podelu inicijalnog skupa instanci na trening i test skup. Argumenti:\n",
    " - **df** - Inicijalni skup instanci,\n",
    " - **test_size** - Veličina test skupa. Ovu veličinu je potrebno zadavati u procentima.\n",
    " \n",
    " Funkcija vraća dve vrednosti: trening i test skup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2019,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size):\n",
    "\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(df))\n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices, k=test_size)\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija **check_purity**, vrši ispitivanje homogenosti skupa prosleđenog kao ulazni (**data**) argument. U slučaju da je prosleđeni skup homogen (vrednost entropije skupa jednaka 0), funkcija vraća *True*, a u slučaju da prosleđeni skup nije homogen (0 < entropija <=1 ), funkcija vraća *False*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2020,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity(data):\n",
    "\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "    \n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija **classify_data**, vrši klasifikaciju prosleđenog skupa (**data** argument) na osnovu poslednje kolone, odnosno atributa. Funkcija se ne bavi ispitivanjem homogenosti prosleđenog skupa, već vrši klasifikaciju na osnovu klase kojoj pripada najveći broj instanci iz prosleđenog skupa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2021,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(data):\n",
    "\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes, count_unique_classes = np.unique(label_column, return_counts=True)\n",
    "    index = count_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija **get_potential_splits** vraća vrednosti svih potencijalnih podela, odnosno mogućih razdelnih vrednosti za svaku kolonu iz prosleđenog (**data**) skupa. Funkcija može vratiti *dictionary*, kao na primer: \n",
    "\n",
    "{0: [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5, 10.5, 11.5, 12.5, 13.5, 14.5, 16.0], 1: [50.0, 56.5, 59.0, 61.5, 63.5, 66.0, 67.5...\n",
    "\n",
    "*Dictionary* je zbog dužine prikazan samo delom. Ključ *dictionary*-ja je indeks kolone **data** skupa (prikazani su samo 0 i 1 indeksi), a vrednosti koje su pridružene svakom ključu su liste koje sadrže sve moguće razdelne vrednosti, odnosno potencijalne podele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2022,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data):\n",
    "\n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "\n",
    "    for column_index in range(n_columns - 1):\n",
    "        potential_splits[column_index] = []\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "        for index in range(len(unique_values)):\n",
    "            if index != 0:\n",
    "                current_value = unique_values[index]\n",
    "                previous_value = unique_values[index - 1]\n",
    "                potential_split = (current_value + previous_value) / 2\n",
    "                potential_splits[column_index].append(potential_split)\n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija: **split_data** vrši podelu prosleđenog skupa instanci. Argumenti:\n",
    " - **data** - skup instanci čija se podela vrši,\n",
    " - **split_column** - indeks kolone na osnovu koje će se vršiti podela,\n",
    " - **split_value** - granična vrednost koja se koristi kao razdelnik pri podeli.\n",
    " \n",
    "Funkcija vraća dve vrednosti: \n",
    " \n",
    " -listu koja sadrži sve vrednosti koje su manje ili jednake graničniku (**split_value**),\n",
    " -listu koja sadrži sve vrednosti koje su veće od granične vrednosti koja se koristi kao razdelnik.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2023,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split_column, split_value):\n",
    "\n",
    "    split_column_values = data[:, split_column]\n",
    "    data_below = data[split_column_values <= split_value]\n",
    "    data_above = data[split_column_values > split_value]\n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija **calculte_entropy** računa entropiju prosleđenog **data** skupa, u odnosu na poslednju kolonu u skupu (voditi računa da klasni atribut na osnovu koga se vrši klasifikacija bude poslednja kolona). Entropija je mera nehomogenosti skupa i kreće se u intervalu [0, 1]. Entropija ima maksimalnu vrednost (1) u slučaju da su sve instance koje čine skup ravnomerno raspoređene po svim klasama, a minimalnu (0) kada sve instance skupa pripadaju jednoj klasi. Entropija se izračunava po formuli:\n",
    "\n",
    "$$ \\sum\\limits_{i = 1}^{n} p_i  * -(\\log_2 p_i) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2024,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(data):\n",
    "\n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija **calculate_overall_entropy** izračunava zbirnu entropiju za dva prosleđena skupa na osnovu sledeće formule:\n",
    "\n",
    "$$ \\sum\\limits_{i = 1}^{2} p_i * entropija $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2025,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_entropy(data_below, data_above):\n",
    "\n",
    "    n_data_points = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n_data_points\n",
    "    p_data_above = len(data_above) / n_data_points\n",
    "\n",
    "    overall_entropy = (p_data_below * calculate_entropy(data_below)\n",
    "                       + p_data_above * calculate_entropy(data_above))\n",
    "\n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija **determine_best_split** određuje najbolju podelu za prosleđeni skup. Argumenti:\n",
    " - **data** - Skup u kome se ispituje koja je najbolja podela. Funkcija određuje najbolju podelu na osnovu vrednosti entropije svake kolone i potencijalne grančne vrednosti individualno (bira najmanju entropiju).\n",
    " - **potential_splits** - *dictionary* koji za svaku kolonu sadrži moguće podele (podele se dobijaju tako što se prvo pozove funkcija **split_data**). Svaka potencijala podela je srednja vrednost između dve susedne vrednosti u koloni.\n",
    " \n",
    "Funkcija vraća dve vrednosti: indeks kolone koju na osnovu koje je najbolje izvršiti podelu i granična vrednost koju treba koristiti pri podeli date kolone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2026,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(data, potential_splits):\n",
    "\n",
    "    overall_entropy = 999\n",
    "\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
    "\n",
    "            if current_overall_entropy <= overall_entropy:\n",
    "                overall_entropy = current_overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "\n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija *decision_tree_algorithm* vrši generisanje stabla odluke i rekurzivnog je karaktera. Svaki poziv funkcije generiše odgovarajuće podstablo koje je oblika: \n",
    "    **{pitanje: [pozitivan_odgovor, negativan_odgovor]}**.\n",
    "Samim tim stablo je realizovano u obliku *dictionary*-ja. Argumenti:\n",
    " - **df** - trening skup koji se koristi za generisanje stabla odluke,\n",
    " - **counter** - kada uzima vrednost 0, funkcija vrši raspakivanje *pandas data frame*-a u *numpy* polje, koje se koristi za potrebe poziva pomoćnih funkcija,\n",
    " - **min_samples** - Budući da se funkcija može koristiti i u svrhu generisanja jednog stabla odluke, pomoću ovog argumenta vrši se odsecanje odnosno *pruning*. Naime, ovaj argument određuje minimalnu vrednost veličine skupa ispod koje se ne vrši dalje razbijanje istog, čak i u slučaju da skup nije homogen. Ukoliko je skup instanci nehomogen, a njegova populacija manja **od min_samples** argumenta, **decision_tree_algorithm** funkcija će izvršiti klasifikaciju na osnovu prisustva najdominantnije klase u skupu. Međutim, imajući u vidu da se u slučaju *random forest algoritma* ne vrši odsecanje individualnog stabla, ovaj argument treba imati vrednost 0, jer se svako stablo koje čini ansambl generiše u potpunosti.   \n",
    " \n",
    "Funkcija vraća generisano stablo odluke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2027,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, counter=0, min_samples=0):\n",
    "\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df\n",
    "\n",
    "    # function is recursive, therefore it should know where to stop\n",
    "    if ((check_purity(data))) or (len(data) < min_samples):\n",
    "        classification = classify_data(data)\n",
    "        return classification\n",
    "    # if data is not pure, enter recursive part\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "        # helper functions\n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column, split_value = determine_best_split(data, potential_splits)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "\n",
    "        # instantiate subtree\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        question = \"{} <= {}\".format(feature_name, split_value)\n",
    "        subtree = {question: []}\n",
    "\n",
    "        # recursive part\n",
    "        yes_answer = decision_tree_algorithm(data_below, counter, min_samples)\n",
    "        no_answer = decision_tree_algorithm(data_above, counter, min_samples)\n",
    "\n",
    "        subtree[question].append(yes_answer)\n",
    "        subtree[question].append(no_answer)\n",
    "\n",
    "        return subtree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija *classify*, vrši klasifikaciju željene instance. Argumenti:\n",
    "   - **example** - instanca čija se klasifikacija vrši,\n",
    "   - **tree** - stablo koje će vršiti klasifikaciju prosleđene instance.\n",
    "    \n",
    "Funkcija vraća utvrđenu klasu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2028,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(example, tree):\n",
    "\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split()\n",
    "\n",
    "    if example[feature_name] <= float(value):\n",
    "        answer = tree[question][0]\n",
    "    else:\n",
    "        answer = tree[question][1]\n",
    "\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    else:\n",
    "        remaining_tree = answer\n",
    "        return classify(example, remaining_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija **create_bootstraped_dataset**, generiše trening skup na osnovu instanci iz skupa koji se prosleđuje kao ulazni argument **df**. Funkcija **create_list_of_bootstraped_dataset** poziva funkciju **create_bootstraped_dataset** onoliko puta koliko je trening skupova potrebno za treniranje svakog individualnih stabala odluke. Instance se prilikom kreiranja individualnog trening skupa biraju nasumično iz prosleđenog skupa, a *random forest* algoritam dozvoljava ponavljanje instanci koje će se naći u trening skupu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2029,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bootstrapped_dataset(df):\n",
    "    original_df_size = len(df)\n",
    "    indices = np.random.randint(0, original_df_size, original_df_size)\n",
    "    bootstrapped_df = df.iloc[indices]\n",
    "    return bootstrapped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija **create_list_of_bootstraped_dataset** kreira trening skup, gde će se svaki individualni skup upotrebiti za generisanje individualnog stabla odluke. Funkcija uzima jedan ulazni argument, **set_size** , koji određuje koliko trening skupova je potrebno generisati.\n",
    "Funkcija vraća listu generisanih trening skupova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2030,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list_of_bootstrapped_dataset(set_size):\n",
    "    bootstrapped_dfs = []\n",
    "    for i in range(set_size):\n",
    "        bootstrapped_dfs.append(create_bootstrapped_dataset(train_df))\n",
    "    return bootstrapped_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pozivom funkcije **generate_random_forest** generišu se stabla na osnovu prosleđenog niza test skupova. Argumenti:\n",
    "   - **number_of_trees** - Broj stabala koja će se generisati,\n",
    "   - **bootstraped_dfs** - Niz trening skupova. Svaki trening skup iz niza koristi se za treniranje individualnog stabla odluke na odgovarajućoj poziciji.\n",
    "   \n",
    "Funkcija vraća niz stabala koja čine ansambl. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2031,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_forest(number_of_trees, bootstrapped_dfs, min_s):\n",
    "    decision_trees = []\n",
    "    for i in range(number_of_trees):\n",
    "        decision_trees.append(decision_tree_algorithm(bootstrapped_dfs[i], min_samples=min_s))\n",
    "    return decision_trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija **vote_classify** vrši klasifikaciju instance na osnovu većinskog glasanja. Argumenti:\n",
    "   - **example** - Instanca čije se klasifikacija vrši,\n",
    "   - **generated_trees** - Niz stabala koja vrše klasifikaciju. \n",
    "\n",
    "Svako stablo vrši individualnu klasifikaciju, a funkcija vraća klasu koja je dobila najveći broj glasova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2032,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote_classify(example, generated_trees):\n",
    "    classification_votes = []\n",
    "\n",
    "    for i in generated_trees:\n",
    "        classification_votes.append(classify(example, i))\n",
    "\n",
    "    unique_votes, number_of_votes = np.unique(classification_votes, return_counts=True)\n",
    "    index = -1\n",
    "    max = 0\n",
    "    for i in range(len(number_of_votes)):\n",
    "        if number_of_votes[i] > max:\n",
    "            max = number_of_votes[i]\n",
    "            index = i\n",
    "\n",
    "    return unique_votes[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcija **test_random_forest_accuracy**  određuje tačnost klasifikacije ansambla stabala odlučivanja. Argumenti:\n",
    " - **test_df** - Skup koji čine instance čija se klasifikacija vrši.\n",
    " - **generated_trees** - Lista stabala koja vrše klasifikaciju\n",
    "\n",
    "Funkcija vraća tri vrednosti: ukupan broj testiranih instanci, broj korektnih klasifikacija i tačnost klasifikacije za zadati skup instanci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2033,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_random_forest_accuracy(test_df, generated_trees):\n",
    "\n",
    "    number_of_correct_classifications = 0\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    for i in range(len(test_df)):\n",
    "        belongs_to_class = vote_classify(test_df.iloc[i], generated_trees)\n",
    "        #print('belongs to class', test_df.iloc[i, -1], 'classified as: ', belongs_to_class)\n",
    "        #print(i, belongs_to_class)\n",
    "        if belongs_to_class == test_df.iloc[i, -1]:\n",
    "            number_of_correct_classifications += 1\n",
    "    #print(number_of_correct_classifications)\n",
    "    #print(test_df)\n",
    "    number_of_instances_tested = len(test_df)\n",
    "    classification_accuracy = number_of_correct_classifications / number_of_instances_tested\n",
    "    return number_of_instances_tested, number_of_correct_classifications, classification_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poslednji deo koda odnosi se na poziv sledećih funkcija:\n",
    " - funkcije koja vrši generisanje trening skupova, \n",
    " - funkcije koja generiše ansambl stabala na osnovu generisanih trening skupova i\n",
    " - funkcije koja vrši testiranje tačnosti klasifikacije generisanog ansambla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2034,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broj testirani instanci:  154\n",
      "Broj tacnih klasifikacija:  117\n",
      "Tacnost random forest algoritma:  0.7597402597402597\n"
     ]
    }
   ],
   "source": [
    "df = replace_missing_values(df)\n",
    "best_features_sorted = determine_best_features(df)\n",
    "df = keep_most_relevant_features(df, 5, best_features_sorted)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "np.random.seed(0)\n",
    "bootstrapped_ds = create_list_of_bootstrapped_dataset(80)\n",
    "generated_trees = generate_random_forest(80, bootstrapped_ds, 0)\n",
    "#pprint(generated_trees)\n",
    "#example = test_df.iloc[1]\n",
    "#print(vote_classify(example, generated_trees))\n",
    "\n",
    "number_of_instances_tested, number_of_correct_classifications, classification_accuracy = test_random_forest_accuracy(test_df, generated_trees)\n",
    "\n",
    "print('Broj testirani instanci: ', number_of_instances_tested)\n",
    "print('Broj tacnih klasifikacija: ', number_of_correct_classifications)\n",
    "print('Tacnost random forest algoritma: ', classification_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Zaključak </center>\n",
    "\n",
    "- Ukoliko se generiše \"ansambl od samo jednog stabla\", tako što će se zahtevati generisanje samo jednog trening skupa, a nakon toga generisanje samo jednog stabla, odnosno:\n",
    "\n",
    "**bootstrapped_ds = create_list_of_bootstrapped_dataset(1)**\n",
    "\n",
    "**generated_trees = generate_random_forest(1, bootstrapped_ds, 0)**,\n",
    "\n",
    "a pri testiranju generisanog stabla koristimo instance koje se nalaze u skupu koji je korišćen za treniranje stabla, odnosno:\n",
    "\n",
    "**test_random_forest_accuracy(bootstrapped_ds[0], generated_trees)**,\n",
    "\n",
    "usled posledica prenaučenja, dobićemo da je tačnost klasifikacije 100% (odnosno 1.0).\n",
    "\n",
    "- Međutim, ukoliko za testiranje generisanog stabla koristimo trening skup:\n",
    "\n",
    "**test_random_forest_accuracy(test_df, generated_trees)**,\n",
    "\n",
    "dobijamo manju tačnost klasifikacije (0.7012987012987013).\n",
    "\n",
    "- U dajem izveštaju, date su tačnosti klasifikacije test skupa za odgovarajući broj zadržanih atributa iz inicijalno učitanog skupa podataka.\n",
    " \n",
    "8 atributa\n",
    "\n",
    "  - 1 - 0.7012987012987013\n",
    "  - 10 - 0.7662337662337663\n",
    "  - 20 - 0.7662337662337663\n",
    "  - 30 - 0.7792207792207793\n",
    "  - 40 - 0.7922077922077922\n",
    "  - 50 - 0.7922077922077922\n",
    "  - 60 - 0.7857142857142857\n",
    "  - 70 - 0.7987012987012987\n",
    "  - 80 - 0.7857142857142857\n",
    "\n",
    "7 atributa\n",
    "\n",
    " - 1 - 0.6753246753246753\n",
    " - 10 - 0.7402597402597403\n",
    " - 20 - 0.7532467532467533\n",
    " - 30 - 0.7727272727272727\n",
    " - 40 - 0.7857142857142857\n",
    " - 50 - 0.7857142857142857\n",
    " - 60 - 0.7857142857142857\n",
    " - 70 - 0.7987012987012987\n",
    " - 80 - 0.7922077922077922\n",
    "\n",
    "6 atributa\n",
    "\n",
    " - 1 - 0.7077922077922078\n",
    " - 10 - 0.7402597402597403\n",
    " - 20 - 0.7467532467532467\n",
    " - 30 - 0.7662337662337663\n",
    " - 40 - 0.7532467532467533\n",
    " - 50 - 0.7597402597402597\n",
    " - 60 - 0.7597402597402597\n",
    " - 70 - 0.7532467532467533\n",
    " - 80 - 0.7597402597402597\n",
    "\n",
    "5 atributa\n",
    "\n",
    " - 1 - 0.7337662337662337\n",
    " - 10 - 0.7467532467532467\n",
    " - 20 - 0.7597402597402597\n",
    " - 30 - 0.7532467532467533\n",
    " - 40 - 0.7662337662337663\n",
    " - 50 - 0.7662337662337663\n",
    " - 60 - 0.7662337662337663\n",
    " - 70 - 0.7597402597402597\n",
    " - 80 - 0.7597402597402597\n",
    "\n",
    "4 atributa\n",
    "\n",
    " - 1- 0.6883116883116883\n",
    " - 10 - 0.7662337662337663\n",
    " - 20 - 0.7597402597402597\n",
    " - 30 - 0.7792207792207793\n",
    " - 40 - 0.7727272727272727\n",
    " - 50 - 0.7727272727272727\n",
    " - 60 - 0.7662337662337663\n",
    " - 70 - 0.7662337662337663\n",
    " - 80 - 0.7662337662337663\n",
    " \n",
    "- Kao što je u uvodu navedeno, ne postoji konkretna metoda kojom se može utvrditi optimalno rešenje, odnosno koji broj stabala daje najtačniju klasifikaciju, već se programeri odlučuju da testiraju tačnost tako što povećavaju populaciju stabala sve dok tačnost klasifikacije raste.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
